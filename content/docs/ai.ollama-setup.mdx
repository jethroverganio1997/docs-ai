---
title: "Ollama Installation, Uninstallation, Reinstallation & Systemd Service Fix Guide"
description: "It covers step-by-step commands to fully remove `Ollama`, reinstall it, configure the ollama user, and ensure the service runs properly in the background using `systemctl`."
---

## üõ†Ô∏è Install Ollama

Run the following command to install Ollama:

```bash
curl -fsSL https://ollama.com/install.sh | sudo sh
```

### ‚öôÔ∏è Run an LLM Model

To run a model (example: Llama 3.2 1B), use:

```
ollama run llama3.2:1b
```

## üî• Uninstall ollama

This guide documents the full set of commands used to completely uninstall Ollama on a Linux server.

```bash
# 1. Stop and disable the Ollama service so it doesn't run on boot
sudo systemctl stop ollama
sudo systemctl disable ollama

# 2. Remove the main Ollama program file
sudo rm -rf /usr/local/bin/ollama

# 3. Remove the service configuration file
sudo rm -f /etc/systemd/system/ollama.service
sudo rm -f which ollama

# 4. Remove the dedicated 'ollama' user and its system data
sudo userdel ollama
sudo rm -r /usr/share/ollama

# 5. Remove all downloaded models and chat history
# WARNING: This step permanently deletes all models.
rm -r ~/.ollama
```

‚úÖ At this stage, ollama should no longer be available:

## üì• Reinstall Ollama

Download and install again:

```bash
curl -fsSL https://ollama.com/install.sh | sudo sh
```

Run llm model from ollama

```bash
ollama run llama3.2:1b
```

### üõ†Ô∏è Fix Systemd Service

If error show like this, fix on the following commands.

<Callout type="error">
  Error ollama server not responding could not connect to ollama server, run
  `ollama serve` to start it
</Callout>

At this point, ollama showed errors because the systemd service was misconfigured.

Steps taken:

1. Edited service file:

```bash
sudo nano /etc/systemd/system/ollama.service
sudo systemctl edit ollama.service 
```

Put inside the `ollama.service`
<Callout>
  OLLAMA HOST should have underscore in between
</Callout>

```yaml
[Unit]
Description=Ollama Service
After=network-online.target

[Service]
ExecStart=/usr/local/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3
Environment="PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin"
Environment="OLLAMA HOST=0.0.0.0"

[Install]
WantedBy=default.target
```

<Callout type="warning">
  Environment=`OLLAMA HOST=0.0.0.0` this allow all incoming to reach ollama set
  to gateway docker IP if you know what your doing
</Callout>

2. Enabled the service:

```bash
sudo systemctl daemon-reload
sudo systemctl enable ollama
sudo systemctl start ollama
```

3. Fix Missing Ollama User

The service failed due to missing ollama user.
Recreated the user and fixed permissions:

```bash
sudo useradd -r -s /bin/false -m -d /usr/share/ollama -g ollama ollama
sudo chown -R ollama:ollama /usr/share/ollama
```

4. Restart & Verify

```
sudo systemctl restart ollama
sudo systemctl status ollama
```

Expected output:

```bash
ollama.service - Ollama Service
     Active: active (running)
     Main PID: XXXX (ollama)
     Listening on [::]:11434 (version 0.12.3)
```

```
sudo ss -tulpn | grep 11434
# Verify Ollama service is listening on port 11434
```

Now you can check models:

```bash
ollama list
```

‚úÖ Final Result
Ollama is installed, running as a systemd service, and responding on port 11434.

## üìö Reference

[ollama](https://ollama.com/download/linux)
